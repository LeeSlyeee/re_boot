"""
ê°•ì˜ ë…¹ìŒ íŒŒì¼ â†’ STT â†’ ìš”ì•½ ê°€ê³µ íŒŒì´í”„ë¼ì¸
1ì‹œê°„ ê°•ì˜ ê¸°ì¤€ ì„¤ê³„ (mp3 ~60MB, wav ~600MB â†’ mp3 ë³€í™˜ í›„ ì²˜ë¦¬)

íŒŒì´í”„ë¼ì¸ íë¦„:
1. ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜ì‹  + ì„ì‹œ ì €ì¥
2. pydubë¡œ 15ë¶„ ë‹¨ìœ„ ì²­í¬ ë¶„í•  (Whisper 25MB ì œí•œ ëŒ€ì‘)
3. ê° ì²­í¬ë¥¼ Whisper APIë¡œ STT ë³€í™˜
4. ì „ì²´ í…ìŠ¤íŠ¸ í•©ì‚° â†’ GPT-4o ìš”ì•½
5. SessionSummary ì €ì¥ + RAG ì¸ë±ì‹±
"""

import os
import math
import tempfile
from pydub import AudioSegment
from openai import OpenAI
from django.conf import settings
from django.utils import timezone

from .models import (
    RecordingUpload, LearningSession, STTLog, SessionSummary
)


# â”€â”€â”€ ì„¤ì • ìƒìˆ˜ â”€â”€â”€
CHUNK_DURATION_MS = 15 * 60 * 1000   # 15ë¶„ ë‹¨ìœ„ (1ì‹œê°„ â†’ 4ì²­í¬)
MAX_FILE_SIZE = 150 * 1024 * 1024     # 150MB (1ì‹œê°„ wavë„ ì»¤ë²„)
WHISPER_MAX_SIZE = 25 * 1024 * 1024   # Whisper API ì œí•œ 25MB
EXPORT_BITRATE = '64k'                # mp3 ë³€í™˜ ì‹œ ë¹„íŠ¸ìœ¨ (15ë¶„ â‰’ 7MB)


def process_recording(recording_id: int) -> dict:
    """
    ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        recording_id: RecordingUploadì˜ PK
    
    Returns:
        dict: { "success": bool, "session_id": int|None, "summary": str|None, "error": str|None }
    """
    recording = RecordingUpload.objects.get(id=recording_id)
    
    try:
        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        
        # â”€â”€ Step 1: ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ â”€â”€
        recording.status = 'SPLITTING'
        recording.save(update_fields=['status'])
        
        audio_path = recording.audio_file.path
        print(f"ğŸ¤ [Pipeline] ì˜¤ë””ì˜¤ ë¡œë“œ: {audio_path}")
        
        audio = AudioSegment.from_file(audio_path)
        duration_sec = len(audio) // 1000
        recording.duration_seconds = duration_sec
        
        total_chunks = math.ceil(len(audio) / CHUNK_DURATION_MS)
        recording.total_chunks = total_chunks
        recording.save(update_fields=['duration_seconds', 'total_chunks'])
        
        print(f"ğŸ“Š [Pipeline] ì´ ê¸¸ì´: {duration_sec}ì´ˆ ({duration_sec // 60}ë¶„), ì²­í¬ ìˆ˜: {total_chunks}")
        
        # â”€â”€ Step 2: ì²­í¬ ë¶„í•  + Whisper STT â”€â”€
        recording.status = 'TRANSCRIBING'
        recording.save(update_fields=['status'])
        
        # LearningSession ìƒì„± (ê°•ì‚¬ ê³„ì •ìœ¼ë¡œ)
        session = LearningSession.objects.create(
            student=recording.uploaded_by,
            lecture=recording.lecture,
            session_order=1,
            is_completed=True,
            end_time=timezone.now()
        )
        recording.session = session
        recording.save(update_fields=['session'])
        
        all_texts = []
        
        for i in range(total_chunks):
            start_ms = i * CHUNK_DURATION_MS
            end_ms = min((i + 1) * CHUNK_DURATION_MS, len(audio))
            chunk = audio[start_ms:end_ms]
            
            # ì„ì‹œ mp3 íŒŒì¼ë¡œ ë³€í™˜ (WhisperëŠ” mp3/wav/m4a ì§€ì›)
            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp:
                chunk.export(tmp.name, format='mp3', bitrate=EXPORT_BITRATE)
                chunk_path = tmp.name
            
            try:
                chunk_size = os.path.getsize(chunk_path)
                print(f"  ğŸ“ [Chunk {i+1}/{total_chunks}] "
                      f"{start_ms//1000//60}ë¶„~{end_ms//1000//60}ë¶„, "
                      f"í¬ê¸°: {chunk_size / 1024 / 1024:.1f}MB")
                
                # Whisper â†’ gpt-4o-transcribe ì—…ê·¸ë ˆì´ë“œ
                with open(chunk_path, 'rb') as audio_file:
                    # ì´ì „ í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì „ë‹¬ (ì •í™•ë„ í–¥ìƒ)
                    previous_context = " ".join(all_texts[-2:])[-200:] if all_texts else ""
                    
                    transcript = client.audio.transcriptions.create(
                        model="gpt-4o-transcribe",
                        file=audio_file,
                        language="ko",
                        prompt=f"ì´ê²ƒì€ í•œêµ­ì–´ IT ë¶€íŠ¸ìº í”„ ê°•ì˜ ìë§‰ì…ë‹ˆë‹¤. ì´ì „ ë‚´ìš©: {previous_context}" if previous_context else "ì´ê²ƒì€ í•œêµ­ì–´ IT ë¶€íŠ¸ìº í”„ ê°•ì˜ ìë§‰ì…ë‹ˆë‹¤.",
                    )
                
                stt_text = transcript.text.strip()
                
                # í™˜ê°(hallucination) í•„í„°ë§
                if _is_hallucination(stt_text):
                    print(f"  âš ï¸ [Chunk {i+1}] í™˜ê° ê°ì§€ â€” ê±´ë„ˆëœ€")
                    stt_text = ""
                
                if stt_text:
                    all_texts.append(stt_text)
                    
                    # STTLog ì €ì¥
                    STTLog.objects.create(
                        session=session,
                        sequence_order=i + 1,
                        text_chunk=stt_text
                    )
                
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if os.path.exists(chunk_path):
                    os.unlink(chunk_path)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            recording.processed_chunks = i + 1
            recording.progress = int(((i + 1) / total_chunks) * 80)  # STT = 80%
            recording.save(update_fields=['processed_chunks', 'progress'])
        
        # â”€â”€ Step 3: AI ìš”ì•½ ìƒì„± â”€â”€
        recording.status = 'SUMMARIZING'
        recording.progress = 85
        recording.save(update_fields=['status', 'progress'])
        
        full_text = "\n\n".join(all_texts)
        
        if not full_text.strip():
            recording.status = 'FAILED'
            recording.error_message = "STT ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ì— ìŒì„±ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
            recording.save(update_fields=['status', 'error_message'])
            return {"success": False, "error": recording.error_message}
        
        print(f"ğŸ“ [Pipeline] ì „ì²´ STT í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}ì")
        
        summary_text = _generate_summary(client, full_text, duration_sec)
        
        if summary_text:
            SessionSummary.objects.create(
                session=session,
                content_text=summary_text,
                raw_stt_link="ë…¹ìŒ íŒŒì¼ ì—…ë¡œë“œ â†’ ê°€ê³µ íŒŒì´í”„ë¼ì¸"
            )
            recording.progress = 95
            recording.save(update_fields=['progress'])
        
        # â”€â”€ Step 4: RAG ì¸ë±ì‹± â”€â”€
        try:
            from .rag import RAGService
            rag = RAGService()
            rag.index_session(session.id)
            print(f"âœ… [Pipeline] RAG ì¸ë±ì‹± ì™„ë£Œ (Session {session.id})")
        except Exception as e:
            print(f"âš ï¸ [Pipeline] RAG ì¸ë±ì‹± ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì ): {e}")
        
        # â”€â”€ ì™„ë£Œ â”€â”€
        recording.status = 'COMPLETED'
        recording.progress = 100
        recording.completed_at = timezone.now()
        recording.save(update_fields=['status', 'progress', 'completed_at'])
        
        print(f"âœ… [Pipeline] íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! Session ID: {session.id}")
        
        return {
            "success": True,
            "session_id": session.id,
            "summary": summary_text,
            "duration_minutes": duration_sec // 60,
            "total_chunks": total_chunks,
            "stt_length": len(full_text),
        }
        
    except Exception as e:
        recording.status = 'FAILED'
        recording.error_message = str(e)
        recording.save(update_fields=['status', 'error_message'])
        print(f"âŒ [Pipeline] ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}


def _is_hallucination(text: str) -> bool:
    """Whisper í™˜ê°(hallucination) í•„í„°"""
    if not text or len(text) < 3:
        return True
    
    HALLUCINATIONS = [
        "ì‹œì²­í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤", "ì‹œì²­í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
        "êµ¬ë…ê³¼ ì¢‹ì•„ìš”", "ì¢‹ì•„ìš”ì™€ êµ¬ë…", "MBC ë‰´ìŠ¤", "SBS ë‰´ìŠ¤",
        "KBS ë‰´ìŠ¤", "Thanks for watching", "Thank you for watching",
        "Subtitles by", "ìë§‰ ì œì‘", "ì˜¤ëŠ˜ë„ ë´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
    ]
    
    for h in HALLUCINATIONS:
        if h in text:
            return True
    
    # ë°˜ë³µ ë¬¸ì ê°ì§€ (ì˜ˆ: "ë·” ë·” ë·” ë·”")
    words = text.split()
    if len(words) >= 3 and len(set(words)) <= 2:
        return True
    
    return False


def _generate_summary(client: OpenAI, full_text: str, duration_sec: int) -> str:
    """
    ê°•ì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ GPT-4oë¡œ ìš”ì•½
    1ì‹œê°„ ë¶„ëŸ‰ì˜ í…ìŠ¤íŠ¸ë„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„
    """
    # 1ì‹œê°„ ê°•ì˜ â‰’ ì•½ 8,000~15,000 ë‹¨ì–´ (í•œêµ­ì–´) â‰’ ì•½ 20,000~40,000 í† í°
    # GPT-4oì˜ 128K ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì•ˆì— ì¶©ë¶„íˆ ë“¤ì–´ê°
    
    duration_min = duration_sec // 60
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë‹¹ì‹ ì€ ëŒ€í•™ ê°•ì˜ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
                        "ì•„ë˜ëŠ” ê°•ì˜ì‹¤ ë…¹ìŒì„ STTë¡œ ì „ì‚¬í•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
                        "ì´ë¥¼ í•™ìƒë“¤ì´ ë³µìŠµí•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì²´ê³„ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\n"
                        "í˜•ì‹:\n"
                        "# ğŸ“š ê°•ì˜ ìš”ì•½\n\n"
                        "## í•µì‹¬ ì£¼ì œ\n- ì£¼ìš” ì£¼ì œ ë‚˜ì—´\n\n"
                        "## ìƒì„¸ ë‚´ìš©\n### 1. ì„¸ë¶€ ì£¼ì œ\n- ì„¤ëª…\n\n"
                        "## í•µì‹¬ í‚¤ì›Œë“œ\n- ì¤‘ìš” ìš©ì–´ì™€ ì§§ì€ ì„¤ëª…\n\n"
                        "## ë³µìŠµ í¬ì¸íŠ¸\n- ì‹œí—˜ì— ë‚˜ì˜¬ ë§Œí•œ í•µì‹¬ ì‚¬í•­"
                    )
                },
                {
                    "role": "user",
                    "content": f"[ê°•ì˜ ì‹œê°„: ì•½ {duration_min}ë¶„]\n\n{full_text}"
                }
            ],
            temperature=0.3,
            max_tokens=4000,
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"âŒ [Summary] GPT-4o ìš”ì•½ ì‹¤íŒ¨: {e}")
        
        # Fallback: ê°„ë‹¨ ìš”ì•½
        lines = full_text.split('\n')
        fallback = f"# ğŸ“š ê°•ì˜ ìš”ì•½ (ìë™ ìƒì„± ì‹¤íŒ¨ â€” ì›ë¬¸ ì¼ë¶€)\n\n"
        fallback += f"**ê°•ì˜ ì‹œê°„**: ì•½ {duration_min}ë¶„\n\n"
        fallback += "## ê°•ì˜ ë‚´ìš© (ì›ë¬¸ ì•ë¶€ë¶„)\n\n"
        fallback += full_text[:3000] + "\n\n..."
        return fallback
